{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PyTorch Computer Vision\n",
        "\n",
        "* See reference notebook - https://github.com/mrdbourke/pytorch-deep-learning/blob/main/03_pytorch_computer_vision.ipynb \n",
        "* See reference online book - https://www.learnpytorch.io/03_pytorch_computer_vision/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Computer vision libaries in PyTorch\n",
        "\n",
        "* [`torchvision`](https://www.learnpytorch.io/03_pytorch_computer_vision/) - base domain library for PyTorch computer vision\n",
        "* `torchvision.datasets` - get datasets and data loading functions for computer vision here\n",
        "* `torchvision.models` - get pretrained computer vision models that you can leverage for your own problems\n",
        "* `torchvision.transforms` - functions for manipulating your vision data (images) to be suitable for use with an ML model\n",
        "* `torch.utils.data.Dataset` - Base dataset class for PyTorch.\n",
        "* `torch.utils.data.DataLoader` - Creates a Python iterable over a dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4.0+cpu\n",
            "0.19.0+cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Import torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Import matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check versions\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Getting a dataset\n",
        "\n",
        "The dataset we'll be using is FashionMNIST from torchvision.datasets - https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup training data\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\", # where to download data to?\n",
        "    train=True, # do we want the training dataset?\n",
        "    download=True, # should we download the data?\n",
        "    transform=torchvision.transforms.ToTensor(), # how do we want to transform the data?\n",
        "    target_transform=None # how do we want to transform the labels/target?\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    target_transform=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 10000)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_data), len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
              "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
              "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
              "           0.0157, 0.0000, 0.0000, 0.0118],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
              "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0471, 0.0392, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
              "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
              "           0.3020, 0.5098, 0.2824, 0.0588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
              "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
              "           0.5529, 0.3451, 0.6745, 0.2588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
              "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
              "           0.4824, 0.7686, 0.8980, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
              "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
              "           0.8745, 0.9608, 0.6784, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
              "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
              "           0.8627, 0.9529, 0.7922, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
              "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
              "           0.8863, 0.7725, 0.8196, 0.2039],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
              "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
              "           0.9608, 0.4667, 0.6549, 0.2196],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
              "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
              "           0.8510, 0.8196, 0.3608, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
              "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
              "           0.8549, 1.0000, 0.3020, 0.0000],\n",
              "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
              "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
              "           0.8784, 0.9569, 0.6235, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
              "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
              "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
              "           0.9137, 0.9333, 0.8431, 0.0000],\n",
              "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
              "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
              "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
              "           0.8627, 0.9098, 0.9647, 0.0000],\n",
              "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
              "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
              "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
              "           0.8706, 0.8941, 0.8824, 0.0000],\n",
              "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
              "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
              "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
              "           0.8745, 0.8784, 0.8980, 0.1137],\n",
              "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
              "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
              "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
              "           0.8627, 0.8667, 0.9020, 0.2627],\n",
              "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
              "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
              "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
              "           0.7098, 0.8039, 0.8078, 0.4510],\n",
              "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
              "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
              "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
              "           0.6549, 0.6941, 0.8235, 0.3608],\n",
              "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
              "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
              "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
              "           0.7529, 0.8471, 0.6667, 0.0000],\n",
              "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
              "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
              "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
              "           0.3882, 0.2275, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
              "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 9)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# See the first training example\n",
        "image, label = train_data[0]\n",
        "image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_names = train_data.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'T-shirt/top': 0,\n",
              " 'Trouser': 1,\n",
              " 'Pullover': 2,\n",
              " 'Dress': 3,\n",
              " 'Coat': 4,\n",
              " 'Sandal': 5,\n",
              " 'Shirt': 6,\n",
              " 'Sneaker': 7,\n",
              " 'Bag': 8,\n",
              " 'Ankle boot': 9}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_to_idx = train_data.class_to_idx\n",
        "class_to_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Check input and output shapes of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image shape: torch.Size([1, 28, 28]) -> [color channel, height, width]\n",
            "Image Label: Ankle boot\n"
          ]
        }
      ],
      "source": [
        "# Check the shape of the image\n",
        "print(f\"Image shape: {image.shape} -> [color channel, height, width]\")\n",
        "print(f\"Image Label: {class_names[label]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Visualizing our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image shape: torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image, label = train_data[0]\n",
        "print(f\"Image shape: {image.shape}\")\n",
        "plt.imshow(image.squeeze(), cmap='gray')\n",
        "plt.title(str(label) + \" - \" + class_names[label])\n",
        "plt.axis('off');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 900x900 with 16 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot more images\n",
        "# torch.manual_seed(42)\n",
        "fig = plt.figure(figsize=(9,9))\n",
        "rows, columns = 4, 4\n",
        "for i in range(1, rows*columns+1):\n",
        "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
        "    img, label = train_data[random_idx]\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.imshow(img.squeeze(), cmap='gray')\n",
        "    plt.title(class_names[label])\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Do you think these items of clothing (images) could be modelled with pure linear lines? Or do you think we'll need non-linearities?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Dataset FashionMNIST\n",
              "     Number of datapoints: 60000\n",
              "     Root location: data\n",
              "     Split: Train\n",
              "     StandardTransform\n",
              " Transform: ToTensor(),\n",
              " Dataset FashionMNIST\n",
              "     Number of datapoints: 10000\n",
              "     Root location: data\n",
              "     Split: Test\n",
              "     StandardTransform\n",
              " Transform: ToTensor())"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data, test_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Prepare DataLoader\n",
        "\n",
        "Right now, our data is in the form of PyTorch Datasets.\n",
        "\n",
        "DataLoader turns our dataset into a Python iterable.\n",
        "\n",
        "More specifically, we want to turn our data into batches (or mini-batches).\n",
        "\n",
        "Why would we do this?\n",
        "\n",
        "1. It is more computationally efficient, as in, your computing hardware may not be able to look (store in memory) at 60000 images in one hit. So we break it down to 32 images at a time (batch size of 32). \n",
        "2. It gives our neural network more chances to update its gradients per epoch.\n",
        "\n",
        "For more on mini-batches, see here: https://youtu.be/l4lSUAcvHFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Turn train dataset into DatLoader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setup the batch size hyperparameter\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataLoaders: <torch.utils.data.dataloader.DataLoader object at 0x0000020FFC5D13D0>, <torch.utils.data.dataloader.DataLoader object at 0x0000020FFC5D18B0>\n",
            "Length of train_dataloader: 1875 batches of 32...\n",
            "Length of test_dataloader: 313 batches of 32...\n"
          ]
        }
      ],
      "source": [
        "# Let's check out what we've created\n",
        "print(f\"DataLoaders: {train_dataloader}, {test_dataloader}\")\n",
        "print(f\"Length of train_dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}...\")\n",
        "print(f\"Length of test_dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check out what's inside the training dataloader\n",
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "train_features_batch.shape, train_labels_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image size: torch.Size([1, 28, 28])\n",
            "Label: 8, label size: torch.Size([])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Show a sample\n",
        "# torch.manual_seed(42)\n",
        "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
        "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[label])\n",
        "plt.axis(False)\n",
        "print(f\"Image size: {img.shape}\")\n",
        "print(f\"Label: {label}, label size: {label.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model 0: Build a basline model\n",
        "\n",
        "When starting to build a series of machine learning modelling experiments, it's best practice to start with a baseline model.\n",
        "\n",
        "A baseline model is a simple model you will try and improve upon with subsequent models/experiments.\n",
        "\n",
        "In other words: start simply and add complexity when necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape before flattening: torch.Size([1, 28, 28]) -> [color_channels, height, width]\n",
            "Shape after flattening: torch.Size([1, 784]) -> [color_channels, height*width]\n"
          ]
        }
      ],
      "source": [
        "# Create a flatten layer\n",
        "flatten_model = nn.Flatten()\n",
        "\n",
        "# Get a single sample\n",
        "x = train_features_batch[0]\n",
        "\n",
        "# Flatten the sample\n",
        "output = flatten_model(x) # perform forward pass\n",
        "\n",
        "# Print out what happened\n",
        "print(f\"Shape before flattening: {x.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Shape after flattening: {output.shape} -> [color_channels, height*width]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "class FashionMNISTModelV0(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_shape: int,\n",
        "                 hidden_units: int,\n",
        "                 output_shape: int):\n",
        "        super().__init__()\n",
        "        self.layer_stack = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "            nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer_stack(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FashionMNISTModelV0(\n",
              "  (layer_stack): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
              "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Setup model with input parameters\n",
        "model_0 = FashionMNISTModelV0(\n",
        "    input_shape= 28*28,\n",
        "    hidden_units=10,\n",
        "    output_shape=len(class_names)\n",
        ").to(\"cpu\")\n",
        "\n",
        "model_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape before flattening: torch.Size([1, 1, 28, 28])\n",
            "Shape after flattening: torch.Size([1, 10])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[-0.0315,  0.3171,  0.0531, -0.2525,  0.5959,  0.2112,  0.3233,  0.2694,\n",
              "         -0.1004,  0.0157]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dummy_x = torch.rand([1, 1, 28, 28])\n",
        "output = model_0(dummy_x)\n",
        "print(f\"Shape before flattening: {dummy_x.shape}\")\n",
        "print(f\"Shape after flattening: {output.shape}\")\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('layer_stack.1.weight',\n",
              "              tensor([[ 0.0273,  0.0296, -0.0084,  ..., -0.0142,  0.0093,  0.0135],\n",
              "                      [-0.0188, -0.0354,  0.0187,  ..., -0.0106, -0.0001,  0.0115],\n",
              "                      [-0.0008,  0.0017,  0.0045,  ..., -0.0127, -0.0188,  0.0059],\n",
              "                      ...,\n",
              "                      [-0.0116,  0.0273, -0.0344,  ...,  0.0176,  0.0283, -0.0011],\n",
              "                      [-0.0230,  0.0257,  0.0291,  ..., -0.0187, -0.0087,  0.0001],\n",
              "                      [ 0.0176, -0.0147,  0.0053,  ..., -0.0336, -0.0221,  0.0205]])),\n",
              "             ('layer_stack.1.bias',\n",
              "              tensor([-0.0093,  0.0283, -0.0033,  0.0255,  0.0017,  0.0037, -0.0302, -0.0123,\n",
              "                       0.0018,  0.0163])),\n",
              "             ('layer_stack.2.weight',\n",
              "              tensor([[ 0.0614, -0.0687,  0.0021,  0.2718,  0.2109,  0.1079, -0.2279, -0.1063,\n",
              "                        0.2019,  0.2847],\n",
              "                      [-0.1495,  0.1344, -0.0740,  0.2006, -0.0475, -0.2514, -0.3130, -0.0118,\n",
              "                        0.0932, -0.1864],\n",
              "                      [ 0.2488,  0.1500,  0.1907,  0.1457, -0.3050, -0.0580,  0.1643,  0.1565,\n",
              "                       -0.2877, -0.1792],\n",
              "                      [ 0.2305, -0.2618,  0.2397, -0.0610,  0.0232,  0.1542,  0.0851, -0.2027,\n",
              "                        0.1030, -0.2715],\n",
              "                      [-0.1596, -0.0555, -0.0633,  0.2302, -0.1726,  0.2654,  0.1473,  0.1029,\n",
              "                        0.2252, -0.2160],\n",
              "                      [-0.2725,  0.0118,  0.1559,  0.1596,  0.0132,  0.3024,  0.1124,  0.1366,\n",
              "                       -0.1533,  0.0965],\n",
              "                      [-0.1184, -0.2555, -0.2057, -0.1909, -0.0477, -0.1324,  0.2905,  0.1307,\n",
              "                       -0.2629,  0.0133],\n",
              "                      [ 0.2727, -0.0127,  0.0513,  0.0863, -0.1043, -0.2047, -0.1185, -0.0825,\n",
              "                        0.2488, -0.2571],\n",
              "                      [ 0.0425, -0.1209, -0.0336, -0.0281, -0.1227,  0.0730,  0.0747, -0.1816,\n",
              "                        0.1943,  0.2853],\n",
              "                      [-0.1310,  0.0645, -0.1171,  0.2168, -0.0245, -0.2820,  0.0736,  0.2621,\n",
              "                        0.0012, -0.0810]])),\n",
              "             ('layer_stack.2.bias',\n",
              "              tensor([-0.0087,  0.1791,  0.2712, -0.0791,  0.1685,  0.1762,  0.2825,  0.2266,\n",
              "                      -0.2612, -0.2613]))])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_0.state_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Setup loss, optimizer and evaluation metrics\n",
        "\n",
        "* Loss function - since we're working with multi-class data, our loss function will be `nn.CrossEntropyLoss()`\n",
        "* Optimizer - our optimizer `torch.optim.SGD()` (stochastic gradient descent)\n",
        "* Evaluation metric - since we're working on a classification problem, let's use accruacy as our evaluation metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "helper_functions.py already exists, skipping download...\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Download helper functions from Learn PyTorch repo\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, skipping download...\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from helper_functions import accuracy_fn\n",
        "\n",
        "# Setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
        "                            lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Creating a function to time our experiments\n",
        "\n",
        "Machine learning is very experimental.\n",
        "\n",
        "Two of the main things you'll often want to track are:\n",
        "1. Model's performance (loss and accuracy values etc)\n",
        "2. How fast it runs "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "from timeit import default_timer as timer\n",
        "def print_train_time(start: float,\n",
        "                     end: float,\n",
        "                     device: torch.device = None):\n",
        "    \"\"\"Prints difference between start and end time.\"\"\"\n",
        "    total_time = end - start\n",
        "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "    return total_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train time on CPU: 0.000 seconds\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.160000000055561e-05"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "start_time = timer()\n",
        "# some code...\n",
        "end_time = timer()\n",
        "print_train_time(start_time, end_time, device=\"CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Creating a training loop and training a model on batches of data\n",
        "\n",
        "1. Loop through epochs.\n",
        "2. Loop through training batches, perform training steps, calculate the train loss *per batch*.\n",
        "3. Loop through testing batches, perform testing steps, calculate the test loss *per batch*.\n",
        "4. Print out what's happening.\n",
        "5. Time it all (for fun).\n",
        "\n",
        "**Note:** Because we are computing on *batches*, the optimizer will update the model's parameters once *per batch* rather than once per epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\esteb\\miniconda3\\envs\\cuda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Looked at 0/60000 samples.\n",
            "Looked at 12800/60000 samples.\n",
            "Looked at 25600/60000 samples.\n",
            "Looked at 38400/60000 samples.\n",
            "Looked at 51200/60000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 1/3 [00:03<00:07,  3.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.5904 | Test loss: 0.5095, Test acc: 82.0387\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Looked at 0/60000 samples.\n",
            "Looked at 12800/60000 samples.\n",
            "Looked at 25600/60000 samples.\n",
            "Looked at 38400/60000 samples.\n",
            "Looked at 51200/60000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 2/3 [00:07<00:03,  3.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.4763 | Test loss: 0.4799, Test acc: 83.1969\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Looked at 0/60000 samples.\n",
            "Looked at 12800/60000 samples.\n",
            "Looked at 25600/60000 samples.\n",
            "Looked at 38400/60000 samples.\n",
            "Looked at 51200/60000 samples.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:10<00:00,  3.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.4550 | Test loss: 0.4766, Test acc: 83.4265\n",
            "Train time on cpu: 10.747 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Import tqdm for progress bars\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Set the seed and start the timer\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_cpu = timer()\n",
        "\n",
        "# Set the number of epochs (we'll keep this small for faster training time)\n",
        "NUM_EPOCHS = 3\n",
        "\n",
        "# Create training and test loop\n",
        "\n",
        "for epoch in tqdm(range(NUM_EPOCHS)):\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    ### Training\n",
        "    train_loss = 0\n",
        "    # Add a loop to loop through the training batches\n",
        "    for batch, (X, y) in enumerate(train_dataloader):\n",
        "        model_0.train()\n",
        "        # 1. Forward pass\n",
        "        y_pred = model_0(X)\n",
        "\n",
        "        # 2. Calculate loss\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss # accumulate train loss\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "    \n",
        "        # Print out what's happening\n",
        "        if batch % 400 == 0:\n",
        "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples.\")\n",
        "\n",
        "    # Divide total train loss by length of train dataloader to get average train loss\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "\n",
        "    ### Testing\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model_0.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X_test, y_test in test_dataloader:\n",
        "            test_pred = model_0(X_test) # forward pass  \n",
        "            test_loss += loss_fn(test_pred, y_test) # accumulate test loss\n",
        "            test_acc += accuracy_fn(y_test, test_pred.argmax(dim=1)) # accumulate test accuracy\n",
        "        \n",
        "        # Calculate the test loss average per batch\n",
        "        test_loss /= len(test_dataloader)\n",
        "\n",
        "        # Calculate the test accuracy average per batch\n",
        "        test_acc /= len(test_dataloader)\n",
        "\n",
        "    # Print out the final test loss and test accuracy\n",
        "    print(f\"\\nTrain loss: {train_loss:.4f} | Test loss: {test_loss:.4f}, Test acc: {test_acc:.4f}\")\n",
        "\n",
        "# Calculate total training time\n",
        "train_time_end_on_cpu = timer()\n",
        "total_train_time_model_0 = print_train_time(train_time_start_on_cpu,\n",
        "                                            train_time_end_on_cpu,\n",
        "                                            device=str(next(model_0.parameters()).device))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(model_0.parameters()).device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Make predictions and get Model 0 results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:00<00:00, 763.28it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'model_name': 'FashionMNISTModelV0',\n",
              " 'model_loss': 0.47663894295692444,\n",
              " 'model_acc': 83.42651757188499}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn,\n",
        "               device = None):\n",
        "    \"\"\"Returns a dictionary containing the results of model predicting on data_loader.\"\"\"\n",
        "    # Set the model to evaluation mode\n",
        "    loss, acc = 0, 0\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in tqdm(data_loader):\n",
        "            # Move data to the device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            # Make predictions\n",
        "            y_pred = model(X)\n",
        "\n",
        "            # Accumulate the loss and acc values per batch\n",
        "            loss += loss_fn(y_pred, y)\n",
        "            acc += accuracy_fn(y_true=y,\n",
        "                               y_pred=y_pred.argmax(dim=1))\n",
        "            \n",
        "        # Scale loss and acc to find the average loss/acc per batch\n",
        "        loss /= len(data_loader)\n",
        "        acc /= len(data_loader)\n",
        "\n",
        "    return{\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
        "           \"model_loss\": loss.item(),\n",
        "           \"model_acc\": acc}\n",
        "\n",
        "# Calculate model 0 results on test dataset\n",
        "model_0_results = eval_model(model = model_0,\n",
        "                             data_loader=test_dataloader,\n",
        "                             loss_fn=loss_fn,\n",
        "                             accuracy_fn=accuracy_fn)\n",
        "model_0_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Setup device agnostic-code (for using a GPU if there is one)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model 1: Building a better model with non-linearity \n",
        "\n",
        "We learned about the power of non-linearity in notebook 02 - https://www.learnpytorch.io/02_pytorch_classification/#6-the-missing-piece-non-linearity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FashionMNISTModelV1(\n",
              "  (layer_stack): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=10, out_features=10, bias=True)\n",
              "    (4): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch import nn\n",
        "\n",
        "class FashionMNISTModelV1(nn.Module):\n",
        "    def __init__(self, input_shape, hidden_units, output_shape):\n",
        "        super().__init__()\n",
        "        self.layer_stack = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer_stack(x)\n",
        "    \n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "model_1 = FashionMNISTModelV1(\n",
        "    input_shape= 28*28,\n",
        "    hidden_units=10,\n",
        "    output_shape=len(class_names)\n",
        ").to(device)\n",
        "\n",
        "model_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
        "                            lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 Functionizing training and evaluation/testing loops \n",
        "\n",
        "Let's create a function for:\n",
        "* training loop - `train_step()`\n",
        "* testing loop - `test_step()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device: torch.device = device):\n",
        "    \n",
        "    \"\"\"Performs a training with model trying to learn on data_loader.\"\"\"\n",
        "\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    # Put model into training mode\n",
        "    model.train()\n",
        "\n",
        "    for batch, (X, y) in enumerate(data_loader):\n",
        "        # Put data on target device\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # 2. Calculate loss and accuracy\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss\n",
        "        train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1)) # go from logits -> predictions labels\n",
        "\n",
        "        # 3. Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "    # Calculate average train loss and acc\n",
        "    train_loss /= len(data_loader)\n",
        "    train_acc /= len(data_loader)\n",
        "    print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "              data_loader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device: torch.device = device):\n",
        "    \"\"\"Performs a test step on model with data_loader.\"\"\"\n",
        "\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    # Put model into evaluation mode\n",
        "    model.eval()\n",
        "    # Turn on inference mode context manager\n",
        "    with torch.inference_mode():\n",
        "        for X_test, y_test in data_loader:\n",
        "            # Put data on target device\n",
        "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "            test_logits = model(X_test) # forward pass\n",
        "            test_loss += loss_fn(test_logits, y_test) # accumulate test loss\n",
        "            test_acc += accuracy_fn(y_true=y_test, y_pred=test_logits.argmax(dim=1)) # accumulate test accuracy\n",
        "\n",
        "        # Calculate average test loss and acc\n",
        "        test_loss /= len(data_loader)\n",
        "        test_acc /= len(data_loader)\n",
        "        print(f\"Test loss: {test_loss:.5f} | Test acc: {test_acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.09199 | Train acc: 61.34%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 1/3 [00:03<00:07,  3.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.95636 | Test acc: 65.00%\n",
            "Train loss: 0.78097 | Train acc: 71.94%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 2/3 [00:07<00:03,  3.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.72611 | Test acc: 73.99%\n",
            "Train loss: 0.67040 | Train acc: 75.94%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:10<00:00,  3.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.69007 | Test acc: 74.81%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Import tqdm for progress bars\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Set the seed and start the timer\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_cpu = timer()\n",
        "\n",
        "# Set the number of epochs (we'll keep this small for faster training time)\n",
        "NUM_EPOCHS = 3\n",
        "\n",
        "for epoch in tqdm(range(NUM_EPOCHS)):\n",
        "    ### Training\n",
        "    train_step(model=model_1,\n",
        "               data_loader=train_dataloader,\n",
        "               loss_fn=loss_fn,\n",
        "               optimizer=optimizer,\n",
        "               accuracy_fn=accuracy_fn,\n",
        "               device=device)\n",
        "    \n",
        "    ### Testing\n",
        "    test_step(model=model_1,\n",
        "              data_loader=test_dataloader,\n",
        "              loss_fn=loss_fn,\n",
        "              accuracy_fn=accuracy_fn,\n",
        "              device=device)\n",
        "    \n",
        "# Calculate total training time\n",
        "train_time_end_on_cpu = timer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:00<00:00, 774.11it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'model_name': 'FashionMNISTModelV1',\n",
              " 'model_loss': 0.6900655031204224,\n",
              " 'model_acc': 74.810303514377}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_1_results = eval_model(model=model_1,\n",
        "                                data_loader=test_dataloader,\n",
        "                                loss_fn=loss_fn,\n",
        "                                accuracy_fn=accuracy_fn)\n",
        "model_1_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model_name': 'FashionMNISTModelV0',\n",
              " 'model_loss': 0.47663894295692444,\n",
              " 'model_acc': 83.42651757188499}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_0_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Note:** Sometimes, depending on your data/hardware you might find that your model trains faster on CPU than GPU.\n",
        "> \n",
        "> Why is this?\n",
        ">\n",
        "> 1. It could be that the overhead for copying data/model to and from the GPU outweighs the compute benefits offered by the GPU.\n",
        "> 2. The hardware you're using has a better CPU in terms compute capability than the GPU.\n",
        ">\n",
        "> For more on how to make your models compute faster, see here: https://horace.io/brrr_intro.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 2: Building a Convolutional Neural Network (CNN)\n",
        "\n",
        "CNN's are also known ConvNets.\n",
        "\n",
        "CNN's are known for their capabilities to find patterns in visual data.\n",
        "\n",
        "To find out what's happening inside a CNN, see this website: https://poloclub.github.io/cnn-explainer/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a convolutional neural network\n",
        "class FashionMNISTModelV2(nn.Module):\n",
        "    \"\"\"Model architecture that replicates the TinyVGG model from CNN explainer website.\"\"\"\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.conv_block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1), # values we can set ourselves in our NN's are called hyperparameters\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2)\n",
        "        )\n",
        "\n",
        "        self.conv_block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                        out_channels=hidden_units,\n",
        "                        kernel_size=3,\n",
        "                        stride=1,\n",
        "                        padding=1), # values we can set ourselves in our NN's are called hyperparameters\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                        out_channels=hidden_units,\n",
        "                        kernel_size=3,\n",
        "                        stride=1,\n",
        "                        padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                            stride=2)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=hidden_units*0, # there's a trick to calculating this...\n",
        "                      out_features=output_shape)\n",
        "        )\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.conv_block_1(x)\n",
        "            print(x.shape)\n",
        "            x = self.conv_block_2(x)\n",
        "            print(X.shape)\n",
        "            x = self.classifier(x)\n",
        "            return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\esteb\\miniconda3\\envs\\cuda\\lib\\site-packages\\torch\\nn\\init.py:453: UserWarning: Initializing zero-element tensors is a no-op\n",
            "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "model_2 = FashionMNISTModelV2(input_shape=image.shape[0],\n",
        "                              hidden_units=10,\n",
        "                              output_shape=len(class_names)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('conv_block_1.0.weight',\n",
              "              tensor([[[[ 2.7393e-02, -8.5299e-02, -6.3802e-02],\n",
              "                        [ 1.5381e-03,  1.4659e-02,  5.8217e-02],\n",
              "                        [-7.4044e-02,  3.3646e-02,  5.9914e-02]],\n",
              "              \n",
              "                       [[ 5.8530e-02, -9.8180e-02, -4.0225e-02],\n",
              "                        [-9.0606e-02, -6.6704e-02,  5.8711e-02],\n",
              "                        [-1.5740e-02,  4.4769e-02, -6.1876e-02]],\n",
              "              \n",
              "                       [[ 1.6018e-02, -6.3758e-02,  5.2693e-02],\n",
              "                        [-4.6104e-02, -2.6432e-02, -9.1456e-02],\n",
              "                        [ 3.4823e-04,  1.0008e-01,  5.1163e-02]],\n",
              "              \n",
              "                       [[-5.6240e-02,  1.4176e-03, -1.1558e-02],\n",
              "                        [-8.4862e-02,  8.2650e-02,  1.6993e-03],\n",
              "                        [ 2.2199e-02, -4.2567e-02, -4.9323e-02]],\n",
              "              \n",
              "                       [[ 1.7381e-02,  3.8971e-02,  2.3643e-02],\n",
              "                        [-5.0801e-02,  1.0234e-01, -1.5517e-02],\n",
              "                        [-6.4554e-02, -4.9301e-02,  1.0377e-01]],\n",
              "              \n",
              "                       [[ 5.0738e-06, -1.4309e-02, -4.3867e-02],\n",
              "                        [-2.7633e-02, -8.8779e-02, -8.3767e-02],\n",
              "                        [ 6.1695e-02,  9.0172e-02,  1.0059e-01]],\n",
              "              \n",
              "                       [[-7.6099e-02,  5.7012e-02, -6.5245e-02],\n",
              "                        [ 6.2883e-02,  7.6058e-02,  8.1573e-02],\n",
              "                        [ 7.5900e-02,  6.5941e-02,  2.0517e-03]],\n",
              "              \n",
              "                       [[ 4.8434e-02, -3.7712e-02,  4.5899e-02],\n",
              "                        [-3.3879e-02, -1.7700e-03, -9.1746e-02],\n",
              "                        [-2.7562e-02, -5.5432e-02, -3.5557e-02]],\n",
              "              \n",
              "                       [[-6.7313e-02, -9.4810e-02,  6.8639e-03],\n",
              "                        [ 6.8408e-02,  9.6001e-02,  6.1512e-02],\n",
              "                        [-5.4638e-02, -1.0425e-01,  3.9983e-02]],\n",
              "              \n",
              "                       [[ 5.9062e-02, -9.0495e-02,  3.7798e-02],\n",
              "                        [ 8.9121e-02,  6.3853e-03, -6.3505e-02],\n",
              "                        [ 8.6423e-02,  4.5011e-02,  6.9802e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-7.1287e-02,  6.1342e-02, -7.2002e-02],\n",
              "                        [ 1.0430e-01, -4.4662e-02,  6.3516e-02],\n",
              "                        [ 2.1107e-02,  2.7935e-02, -1.6165e-02]],\n",
              "              \n",
              "                       [[ 4.3295e-02, -4.3932e-02, -9.9357e-02],\n",
              "                        [-4.0499e-02,  8.2592e-02, -2.7751e-02],\n",
              "                        [ 3.3132e-02, -3.8973e-02,  7.9073e-02]],\n",
              "              \n",
              "                       [[ 6.3086e-02,  3.7211e-02, -5.3881e-02],\n",
              "                        [-8.6133e-02,  3.9686e-03, -6.1839e-02],\n",
              "                        [ 8.6667e-02, -1.0130e-01,  4.7104e-02]],\n",
              "              \n",
              "                       [[ 1.0508e-01,  5.2792e-02,  3.5942e-02],\n",
              "                        [-1.0142e-01,  1.0139e-01, -1.8030e-02],\n",
              "                        [-9.8495e-02,  1.0406e-01, -4.2894e-02]],\n",
              "              \n",
              "                       [[-7.4575e-03,  9.6479e-02, -7.3070e-02],\n",
              "                        [-7.4576e-02,  1.7141e-02, -1.4109e-02],\n",
              "                        [ 2.4280e-02, -8.8407e-02,  3.1524e-03]],\n",
              "              \n",
              "                       [[-4.6882e-02, -5.1820e-02, -9.6517e-02],\n",
              "                        [ 5.5890e-02,  2.0306e-02, -8.9118e-02],\n",
              "                        [ 8.3648e-02,  3.1794e-02,  1.9560e-02]],\n",
              "              \n",
              "                       [[-6.1890e-02,  1.5896e-02,  1.0157e-01],\n",
              "                        [ 7.2299e-02, -8.2100e-02,  9.6220e-02],\n",
              "                        [ 8.1702e-03,  5.0698e-02,  8.1869e-02]],\n",
              "              \n",
              "                       [[ 8.9862e-02, -8.2170e-02,  9.2303e-02],\n",
              "                        [-7.1591e-02,  7.9021e-03, -7.3656e-02],\n",
              "                        [-2.3109e-02, -4.7901e-03, -1.2611e-02]],\n",
              "              \n",
              "                       [[-1.6652e-02,  8.3137e-03,  1.0398e-01],\n",
              "                        [ 6.1244e-02,  5.8973e-02,  4.2190e-02],\n",
              "                        [ 8.1606e-02, -4.8645e-03,  8.3813e-03]],\n",
              "              \n",
              "                       [[ 2.1693e-02, -9.1931e-02, -8.4913e-02],\n",
              "                        [ 1.2923e-02, -4.1241e-02, -1.9342e-03],\n",
              "                        [-2.4187e-02,  1.6408e-02,  6.8581e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-3.4958e-02,  8.4418e-02,  8.3227e-02],\n",
              "                        [-8.0901e-02, -8.1400e-02, -8.5284e-02],\n",
              "                        [-5.7766e-02, -4.1033e-02, -7.9341e-03]],\n",
              "              \n",
              "                       [[-2.5635e-02, -5.3258e-02, -3.3488e-02],\n",
              "                        [-3.8131e-02,  1.0341e-01, -3.9068e-02],\n",
              "                        [-7.5473e-02,  4.3818e-02, -6.0886e-03]],\n",
              "              \n",
              "                       [[ 8.0698e-02,  6.5863e-02,  9.6843e-02],\n",
              "                        [-7.7197e-02,  6.7764e-02,  8.8464e-02],\n",
              "                        [-5.2054e-02,  9.6890e-02,  7.9019e-02]],\n",
              "              \n",
              "                       [[ 1.1544e-03,  5.0823e-02, -3.6853e-02],\n",
              "                        [-9.1936e-02,  2.6645e-02,  3.1425e-02],\n",
              "                        [-6.8891e-02,  5.1123e-02, -9.0043e-02]],\n",
              "              \n",
              "                       [[ 9.0718e-02,  1.0208e-01,  2.8699e-02],\n",
              "                        [-6.6137e-02,  5.1300e-02,  1.7963e-02],\n",
              "                        [ 2.8663e-02,  3.4643e-02,  8.0254e-02]],\n",
              "              \n",
              "                       [[-4.5309e-02, -2.3711e-02,  2.8746e-02],\n",
              "                        [ 1.1486e-02,  8.5000e-02, -5.5365e-02],\n",
              "                        [-3.8387e-03,  1.9696e-02, -2.7996e-02]],\n",
              "              \n",
              "                       [[ 7.1859e-02,  1.1530e-02, -9.7422e-02],\n",
              "                        [-1.1420e-02, -4.7809e-02,  1.0243e-02],\n",
              "                        [-1.2250e-02, -1.0456e-01, -1.9208e-02]],\n",
              "              \n",
              "                       [[-1.0096e-02, -3.1083e-02,  9.6848e-02],\n",
              "                        [-2.3000e-02,  6.7717e-02,  2.6112e-02],\n",
              "                        [-8.8979e-02,  2.4770e-02,  8.7356e-02]],\n",
              "              \n",
              "                       [[-6.8948e-02, -6.8134e-02,  1.0318e-01],\n",
              "                        [ 8.4697e-02, -5.8807e-02,  6.3429e-02],\n",
              "                        [-1.3485e-02, -1.0393e-01,  7.9198e-03]],\n",
              "              \n",
              "                       [[ 3.4057e-02, -3.1619e-02,  3.6670e-02],\n",
              "                        [-9.0136e-02,  7.3050e-02,  8.9865e-02],\n",
              "                        [ 5.8130e-02,  1.7866e-02,  3.4716e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-7.6269e-02, -2.6339e-02, -1.0063e-02],\n",
              "                        [-5.8659e-02, -7.7857e-02,  7.0900e-02],\n",
              "                        [ 7.1535e-02, -9.5731e-02,  3.3542e-02]],\n",
              "              \n",
              "                       [[ 4.2881e-02,  1.0014e-01,  6.0985e-02],\n",
              "                        [ 9.6907e-02, -3.4510e-02,  7.3827e-02],\n",
              "                        [ 8.5740e-02, -9.9541e-02, -8.4613e-02]],\n",
              "              \n",
              "                       [[ 2.1335e-02,  5.7557e-02, -5.2369e-02],\n",
              "                        [ 1.1609e-02, -1.5303e-04,  2.6680e-02],\n",
              "                        [-5.6642e-02,  5.9455e-02,  7.0098e-02]],\n",
              "              \n",
              "                       [[-7.3139e-02,  1.0211e-03,  2.9247e-04],\n",
              "                        [ 3.3849e-02,  9.8198e-02,  3.0913e-02],\n",
              "                        [-2.3951e-02,  9.4672e-02, -4.0112e-02]],\n",
              "              \n",
              "                       [[-3.0608e-02,  7.1969e-03, -8.0270e-02],\n",
              "                        [ 1.1470e-02, -7.1518e-02,  1.0838e-02],\n",
              "                        [ 1.0099e-02,  1.4591e-02, -8.8891e-02]],\n",
              "              \n",
              "                       [[-1.0012e-01,  4.8501e-02,  9.0399e-02],\n",
              "                        [-9.3537e-02,  3.9043e-02, -7.7594e-02],\n",
              "                        [ 6.6082e-03,  9.8068e-02,  7.9965e-02]],\n",
              "              \n",
              "                       [[-7.7069e-02,  6.5203e-02,  5.5057e-02],\n",
              "                        [-1.6169e-04,  1.0211e-01, -4.1866e-02],\n",
              "                        [-2.4530e-02, -5.3275e-02,  1.5168e-02]],\n",
              "              \n",
              "                       [[ 2.7911e-02,  8.3990e-03, -5.9307e-02],\n",
              "                        [-4.7452e-02,  3.5855e-02, -9.2426e-02],\n",
              "                        [-1.6416e-02, -2.3350e-03, -4.2708e-02]],\n",
              "              \n",
              "                       [[ 3.8360e-02,  6.7940e-03,  7.4004e-02],\n",
              "                        [-9.3616e-03, -6.6528e-02,  7.4477e-02],\n",
              "                        [ 1.4720e-02, -3.0189e-02, -6.9476e-02]],\n",
              "              \n",
              "                       [[ 2.4707e-02, -1.0053e-01,  2.7762e-02],\n",
              "                        [ 5.2119e-02, -9.2465e-02, -6.9009e-02],\n",
              "                        [-7.5781e-02,  8.8597e-02,  8.9611e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 6.5987e-03,  9.8959e-02, -3.5239e-02],\n",
              "                        [-1.0233e-01,  3.6819e-02,  3.7343e-02],\n",
              "                        [ 1.0334e-01, -3.0510e-05,  8.0785e-02]],\n",
              "              \n",
              "                       [[ 6.4612e-02,  7.6292e-02, -1.0460e-01],\n",
              "                        [ 8.6800e-02, -8.9856e-02,  9.4501e-02],\n",
              "                        [-4.3682e-03, -9.3415e-02,  2.9314e-02]],\n",
              "              \n",
              "                       [[-2.1456e-02, -9.4678e-02, -3.8215e-02],\n",
              "                        [ 1.0868e-02,  8.2098e-02, -3.2406e-02],\n",
              "                        [ 6.2610e-02,  1.3200e-02,  3.5531e-03]],\n",
              "              \n",
              "                       [[ 2.0170e-02, -6.9177e-02, -8.7616e-02],\n",
              "                        [-3.3121e-02, -9.8226e-02, -4.9158e-02],\n",
              "                        [ 4.8494e-03, -6.9424e-02, -4.3723e-02]],\n",
              "              \n",
              "                       [[-1.8941e-02, -1.2144e-02, -5.8187e-02],\n",
              "                        [ 5.0650e-03, -1.4795e-02,  3.0147e-02],\n",
              "                        [ 4.7611e-03, -5.2638e-02, -3.6291e-02]],\n",
              "              \n",
              "                       [[-1.2149e-03, -6.5774e-02,  8.2520e-03],\n",
              "                        [-7.4425e-03,  4.0897e-02,  2.4947e-02],\n",
              "                        [ 7.8887e-02, -3.4749e-03, -7.7887e-02]],\n",
              "              \n",
              "                       [[ 4.7119e-02, -7.1240e-02, -1.4489e-02],\n",
              "                        [-3.4132e-02, -3.9997e-02, -3.9000e-02],\n",
              "                        [ 9.6863e-02,  6.0342e-02,  2.9213e-02]],\n",
              "              \n",
              "                       [[ 9.8975e-02, -9.5524e-02,  1.7010e-02],\n",
              "                        [ 6.7481e-02,  7.0022e-02, -8.3890e-02],\n",
              "                        [ 3.7514e-02, -6.0050e-02, -4.1187e-03]],\n",
              "              \n",
              "                       [[-2.1996e-02, -8.8013e-02, -1.0055e-01],\n",
              "                        [-6.9349e-02,  4.7832e-02,  4.8218e-02],\n",
              "                        [-9.1681e-02, -3.9586e-02,  1.7218e-03]],\n",
              "              \n",
              "                       [[-9.1135e-02,  5.9393e-02,  9.5473e-02],\n",
              "                        [ 1.8643e-02, -7.8321e-02,  2.4580e-02],\n",
              "                        [ 3.8265e-02,  8.3468e-02, -5.6085e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-9.4437e-02,  4.6312e-02,  6.5624e-03],\n",
              "                        [-3.4345e-02, -4.4169e-02, -5.4351e-02],\n",
              "                        [ 8.5328e-02, -1.8187e-02,  7.6022e-02]],\n",
              "              \n",
              "                       [[ 9.4094e-02,  1.3353e-02,  2.2454e-02],\n",
              "                        [-7.1789e-03,  7.2397e-02, -9.4983e-02],\n",
              "                        [ 4.1919e-02, -1.7174e-02,  4.8132e-02]],\n",
              "              \n",
              "                       [[-4.6949e-04, -3.9029e-02, -1.1379e-02],\n",
              "                        [ 5.6920e-02, -7.3210e-02, -6.6629e-02],\n",
              "                        [-2.3611e-02, -3.8235e-02,  4.1409e-02]],\n",
              "              \n",
              "                       [[ 7.0937e-02, -1.1289e-02,  9.9672e-02],\n",
              "                        [-4.4042e-02, -5.9151e-02, -4.7191e-02],\n",
              "                        [-7.2624e-02, -7.3885e-02, -9.3921e-02]],\n",
              "              \n",
              "                       [[-9.3422e-02,  2.7512e-02,  6.4284e-02],\n",
              "                        [ 9.8963e-02,  8.9787e-02, -6.0709e-03],\n",
              "                        [ 2.0454e-02, -6.3068e-02,  4.0743e-02]],\n",
              "              \n",
              "                       [[-1.0107e-01,  4.9719e-02,  1.9334e-02],\n",
              "                        [ 3.2393e-02,  3.8595e-02, -4.8394e-02],\n",
              "                        [ 9.0452e-02,  5.0307e-02,  6.9243e-02]],\n",
              "              \n",
              "                       [[ 1.3922e-02,  6.6196e-02,  7.0941e-02],\n",
              "                        [ 4.7775e-02,  8.0297e-02, -1.9119e-02],\n",
              "                        [ 6.9310e-02,  2.4286e-02,  6.3424e-02]],\n",
              "              \n",
              "                       [[ 1.0267e-01,  2.3869e-02, -3.9124e-02],\n",
              "                        [-1.0488e-02,  2.9676e-02,  1.7773e-02],\n",
              "                        [-2.8795e-02,  8.2590e-02,  6.3331e-02]],\n",
              "              \n",
              "                       [[-6.5475e-02, -8.5889e-03, -1.0119e-02],\n",
              "                        [-6.6063e-02,  1.5374e-02, -3.2360e-02],\n",
              "                        [-5.4419e-02, -3.3894e-02, -3.7584e-02]],\n",
              "              \n",
              "                       [[ 1.0084e-01,  4.0432e-02,  1.0373e-01],\n",
              "                        [ 2.8903e-02,  2.3868e-02,  4.3333e-02],\n",
              "                        [ 1.8092e-02, -8.2722e-02, -6.2334e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-2.5538e-02,  1.5846e-03,  3.9709e-02],\n",
              "                        [ 4.0588e-02,  8.3623e-02,  2.1458e-02],\n",
              "                        [-3.5975e-02, -7.9271e-02, -7.7203e-02]],\n",
              "              \n",
              "                       [[-6.2965e-02,  3.1792e-02,  5.6950e-02],\n",
              "                        [ 9.2224e-02, -3.3342e-02, -8.3150e-03],\n",
              "                        [-3.1303e-02, -3.8517e-04,  3.3837e-02]],\n",
              "              \n",
              "                       [[-2.3160e-03,  4.8799e-03,  1.3354e-02],\n",
              "                        [ 3.9256e-02, -3.1981e-02, -6.2855e-02],\n",
              "                        [ 2.4869e-02, -1.2481e-02, -4.7753e-02]],\n",
              "              \n",
              "                       [[ 4.4268e-02,  9.5597e-04, -1.5333e-02],\n",
              "                        [-5.1027e-02, -1.3868e-02, -8.9632e-02],\n",
              "                        [ 2.3980e-02,  1.5818e-03,  6.3966e-02]],\n",
              "              \n",
              "                       [[ 6.8063e-03,  8.4277e-03,  2.8715e-02],\n",
              "                        [ 8.0210e-02, -4.9812e-02,  6.2930e-02],\n",
              "                        [ 2.5779e-02, -7.0320e-02,  3.6702e-02]],\n",
              "              \n",
              "                       [[-6.3217e-02, -3.3181e-02, -5.0245e-02],\n",
              "                        [-7.1711e-02,  8.3017e-02, -9.4217e-02],\n",
              "                        [ 5.2706e-02, -9.4870e-02, -1.2829e-02]],\n",
              "              \n",
              "                       [[ 6.2868e-03,  7.4937e-02, -3.8147e-02],\n",
              "                        [ 3.0340e-02,  1.6329e-02,  6.2021e-02],\n",
              "                        [ 6.2668e-03,  3.9470e-02, -6.3677e-02]],\n",
              "              \n",
              "                       [[-7.3250e-02,  9.3928e-02, -7.6808e-02],\n",
              "                        [-1.7945e-02, -1.2742e-02,  1.0308e-01],\n",
              "                        [-2.2780e-02, -8.0249e-02, -2.6721e-02]],\n",
              "              \n",
              "                       [[ 5.4372e-02,  4.1773e-02,  8.7204e-02],\n",
              "                        [-2.1579e-02,  4.9653e-02, -9.9194e-02],\n",
              "                        [ 4.0787e-02,  4.8432e-02,  6.7998e-02]],\n",
              "              \n",
              "                       [[-6.0446e-02, -2.8142e-02,  2.5502e-02],\n",
              "                        [-7.4905e-02, -8.3851e-02, -1.0141e-01],\n",
              "                        [ 5.8842e-03,  6.5458e-02,  2.7075e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 6.4263e-03,  3.6727e-02, -6.6240e-02],\n",
              "                        [ 1.1113e-02, -2.6186e-02, -5.2193e-02],\n",
              "                        [ 9.0902e-02, -8.1550e-02,  1.5448e-02]],\n",
              "              \n",
              "                       [[-9.2624e-02, -3.5762e-03, -4.6840e-02],\n",
              "                        [ 3.4695e-02, -5.9191e-02,  6.7466e-02],\n",
              "                        [-8.5536e-02,  6.3313e-02, -7.9181e-02]],\n",
              "              \n",
              "                       [[ 5.6456e-02, -4.4384e-02, -2.4556e-04],\n",
              "                        [-1.9238e-02,  6.8414e-02,  3.4546e-02],\n",
              "                        [-9.2887e-02,  9.6914e-03, -7.2718e-02]],\n",
              "              \n",
              "                       [[ 7.8800e-02,  1.7319e-02, -2.7109e-02],\n",
              "                        [-5.3777e-02,  3.6485e-02, -6.3129e-02],\n",
              "                        [ 4.9992e-02,  5.7519e-02,  6.4701e-02]],\n",
              "              \n",
              "                       [[ 2.7537e-02, -9.2272e-02,  7.5823e-02],\n",
              "                        [-3.2700e-02, -3.1163e-02, -1.1325e-02],\n",
              "                        [ 7.7068e-02,  8.1052e-02,  1.6276e-02]],\n",
              "              \n",
              "                       [[ 5.0296e-02, -9.8241e-02,  2.4901e-04],\n",
              "                        [-9.3254e-02,  3.5876e-02, -7.5099e-02],\n",
              "                        [-3.7568e-02,  7.3684e-02,  1.0074e-01]],\n",
              "              \n",
              "                       [[-6.3286e-02, -5.8503e-02,  1.3055e-02],\n",
              "                        [ 4.1437e-02, -1.7168e-02, -3.2918e-02],\n",
              "                        [-6.9237e-02,  4.4997e-02,  1.0328e-01]],\n",
              "              \n",
              "                       [[-5.1026e-02,  4.9718e-02,  5.1481e-02],\n",
              "                        [ 8.4728e-02, -1.2001e-02,  3.3202e-03],\n",
              "                        [ 7.7444e-02,  6.6631e-02,  1.0411e-01]],\n",
              "              \n",
              "                       [[-3.0207e-02,  4.1709e-02,  7.3605e-02],\n",
              "                        [-7.1553e-02,  2.0940e-02, -2.3586e-02],\n",
              "                        [ 6.7760e-02, -4.7342e-02,  7.3933e-03]],\n",
              "              \n",
              "                       [[ 6.3067e-02, -9.6567e-02, -8.9004e-02],\n",
              "                        [-5.3989e-02,  6.7611e-02,  7.0680e-02],\n",
              "                        [-7.1991e-02,  2.0100e-02, -5.5854e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-4.8926e-02,  9.0907e-02,  5.0914e-02],\n",
              "                        [-2.8828e-02,  1.5516e-02,  2.0424e-02],\n",
              "                        [ 2.4691e-02, -3.6079e-02, -6.2074e-02]],\n",
              "              \n",
              "                       [[ 6.9788e-02,  1.4164e-02,  4.4119e-02],\n",
              "                        [-3.9922e-02,  5.1057e-02,  7.6713e-02],\n",
              "                        [ 6.4107e-02,  2.8660e-02,  1.0371e-01]],\n",
              "              \n",
              "                       [[-2.3053e-04,  2.2441e-02,  1.0015e-01],\n",
              "                        [ 1.0245e-01, -4.4506e-02,  9.4953e-02],\n",
              "                        [ 3.8902e-02, -1.1799e-02,  9.2038e-02]],\n",
              "              \n",
              "                       [[-5.4605e-02,  6.8490e-02,  1.0445e-01],\n",
              "                        [-7.2701e-02, -6.2201e-02, -1.0445e-01],\n",
              "                        [-1.8970e-02, -9.5733e-02, -3.5304e-02]],\n",
              "              \n",
              "                       [[ 3.2002e-02,  7.4511e-02,  5.8717e-02],\n",
              "                        [ 5.8511e-02,  4.3730e-02, -6.5378e-02],\n",
              "                        [-8.3694e-02,  4.3696e-03,  1.0009e-01]],\n",
              "              \n",
              "                       [[ 5.9351e-03, -9.0662e-03, -7.1545e-02],\n",
              "                        [-5.2266e-02, -8.1256e-02,  8.4398e-02],\n",
              "                        [-1.7174e-02, -9.3119e-02,  1.1308e-02]],\n",
              "              \n",
              "                       [[ 7.6494e-03, -1.3023e-02,  3.7733e-02],\n",
              "                        [ 5.6687e-02, -9.9128e-02, -8.0753e-02],\n",
              "                        [-5.0639e-03, -9.7729e-02, -9.5750e-02]],\n",
              "              \n",
              "                       [[ 9.3067e-02, -8.0174e-03, -5.2113e-02],\n",
              "                        [-3.6157e-02, -8.2295e-02,  8.2258e-02],\n",
              "                        [-2.2857e-02, -5.9265e-02, -7.9944e-02]],\n",
              "              \n",
              "                       [[ 6.1611e-02, -1.4571e-02, -1.1074e-02],\n",
              "                        [-2.7473e-02, -5.0883e-02,  1.8751e-02],\n",
              "                        [ 8.1099e-02, -6.1093e-02,  5.0504e-03]],\n",
              "              \n",
              "                       [[-8.0165e-02, -4.9426e-02,  9.2525e-02],\n",
              "                        [ 1.1052e-03,  1.0154e-01, -1.8468e-02],\n",
              "                        [-5.7453e-02, -6.2981e-02,  9.3426e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-8.1058e-02,  5.5318e-02,  2.6203e-02],\n",
              "                        [ 3.1107e-02,  5.9476e-02, -2.7577e-02],\n",
              "                        [ 6.5223e-02, -8.3982e-02, -3.7087e-02]],\n",
              "              \n",
              "                       [[ 7.7164e-02,  3.1283e-02, -1.4038e-02],\n",
              "                        [-2.4616e-02, -6.4364e-02,  6.4098e-02],\n",
              "                        [-3.3520e-03, -3.5664e-03,  2.4929e-02]],\n",
              "              \n",
              "                       [[ 7.7787e-02, -5.3778e-02, -3.6303e-02],\n",
              "                        [ 7.1429e-02,  5.9532e-02, -5.1855e-02],\n",
              "                        [-1.0428e-01,  1.9555e-02,  5.5434e-02]],\n",
              "              \n",
              "                       [[ 2.5178e-02,  7.4768e-02, -8.3640e-02],\n",
              "                        [ 5.3156e-02, -6.5531e-02,  5.9325e-02],\n",
              "                        [ 7.8394e-02,  3.3385e-02,  8.5284e-02]],\n",
              "              \n",
              "                       [[-6.9481e-02, -9.4275e-02, -1.0135e-01],\n",
              "                        [ 6.6179e-02,  3.6926e-02, -7.7188e-02],\n",
              "                        [ 5.1048e-02,  9.6177e-02, -1.0394e-01]],\n",
              "              \n",
              "                       [[ 7.6466e-02,  1.6167e-02,  9.8053e-03],\n",
              "                        [ 9.4847e-02,  9.5458e-02,  4.4414e-02],\n",
              "                        [ 8.3288e-02,  4.3853e-02,  1.7176e-02]],\n",
              "              \n",
              "                       [[-9.2656e-02,  1.9689e-02, -7.4993e-02],\n",
              "                        [ 3.2452e-02,  1.8598e-02,  2.3681e-03],\n",
              "                        [-7.2071e-02, -6.3899e-02,  7.7912e-02]],\n",
              "              \n",
              "                       [[ 5.1336e-02,  5.5576e-02, -3.1410e-02],\n",
              "                        [-1.8151e-02, -2.7014e-02,  7.2489e-02],\n",
              "                        [-4.5504e-02,  6.6394e-02,  7.2679e-02]],\n",
              "              \n",
              "                       [[-9.6403e-02,  6.4369e-04, -2.0076e-02],\n",
              "                        [-5.8273e-02,  4.5507e-02, -1.2807e-02],\n",
              "                        [ 9.2287e-02, -6.5976e-02,  4.8976e-02]],\n",
              "              \n",
              "                       [[-8.9998e-02, -5.2833e-02,  7.1903e-03],\n",
              "                        [ 8.3283e-02,  5.5521e-02, -8.6550e-02],\n",
              "                        [ 1.1676e-02, -6.2138e-02,  4.5674e-03]]]])),\n",
              "             ('conv_block_1.0.bias',\n",
              "              tensor([-0.0878, -0.0309,  0.0723, -0.0967, -0.1005,  0.0192,  0.0144, -0.0193,\n",
              "                       0.0920, -0.0635])),\n",
              "             ('conv_block_1.2.weight',\n",
              "              tensor([[[[-6.3992e-02, -7.8791e-02, -1.9619e-02],\n",
              "                        [-2.6901e-02,  6.5222e-02, -5.9186e-03],\n",
              "                        [ 3.3663e-02, -4.3804e-02,  8.5507e-02]],\n",
              "              \n",
              "                       [[ 8.8862e-02, -9.4401e-02, -2.7090e-02],\n",
              "                        [-8.9439e-02,  4.4781e-02, -9.2094e-02],\n",
              "                        [-4.9839e-02,  1.0532e-01, -1.0066e-01]],\n",
              "              \n",
              "                       [[ 7.7771e-02,  8.9049e-03,  8.4289e-02],\n",
              "                        [-5.3494e-02,  6.9236e-02,  1.2718e-02],\n",
              "                        [ 8.1073e-03,  7.1945e-02, -1.0019e-01]],\n",
              "              \n",
              "                       [[-8.4902e-02,  1.0180e-01, -6.3298e-02],\n",
              "                        [-7.5980e-02, -5.1539e-03, -3.3742e-02],\n",
              "                        [-1.4421e-02, -7.0623e-02,  3.8034e-02]],\n",
              "              \n",
              "                       [[-9.0703e-02,  8.5374e-03,  6.1510e-02],\n",
              "                        [ 2.0253e-02,  1.4006e-02,  1.5418e-02],\n",
              "                        [-3.0880e-02, -2.0080e-02, -4.4450e-02]],\n",
              "              \n",
              "                       [[-7.1207e-02, -5.5810e-02,  1.0420e-01],\n",
              "                        [-1.7641e-02,  3.6924e-02,  7.2896e-02],\n",
              "                        [-8.2343e-03, -5.6707e-02, -7.1419e-02]],\n",
              "              \n",
              "                       [[-3.8833e-02,  3.7624e-02, -8.8771e-02],\n",
              "                        [-1.2870e-02,  4.0096e-02,  8.5999e-02],\n",
              "                        [ 3.1721e-02,  2.0846e-02,  7.2162e-02]],\n",
              "              \n",
              "                       [[ 4.8708e-02,  3.5661e-02, -3.2682e-02],\n",
              "                        [-8.4528e-02, -2.2769e-02, -1.9117e-02],\n",
              "                        [ 7.7410e-03, -1.1593e-02,  4.2616e-02]],\n",
              "              \n",
              "                       [[ 7.0050e-02, -4.2735e-02, -1.0002e-01],\n",
              "                        [-5.4081e-02, -5.0436e-02,  5.9750e-02],\n",
              "                        [-6.7994e-02, -9.9145e-03, -2.2340e-02]],\n",
              "              \n",
              "                       [[-6.3976e-02,  4.7780e-02, -4.3909e-02],\n",
              "                        [-5.4531e-03, -7.4112e-02, -1.0632e-02],\n",
              "                        [ 1.4977e-02, -4.2894e-03, -3.9386e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 3.1315e-02, -2.7311e-02, -5.8439e-02],\n",
              "                        [-7.7732e-02, -2.2329e-02, -9.9578e-02],\n",
              "                        [ 8.7492e-02, -5.0357e-02, -4.3684e-02]],\n",
              "              \n",
              "                       [[ 9.7439e-03,  2.7326e-02, -9.9393e-03],\n",
              "                        [ 7.2313e-02, -6.1448e-02,  3.7777e-02],\n",
              "                        [-2.3773e-04, -8.5747e-02, -4.0824e-02]],\n",
              "              \n",
              "                       [[ 2.6825e-02,  2.0138e-02,  7.6647e-02],\n",
              "                        [ 7.0518e-02, -5.7493e-02, -4.5013e-02],\n",
              "                        [-2.2351e-02, -7.5517e-02, -2.8459e-02]],\n",
              "              \n",
              "                       [[-8.6258e-02,  4.0092e-02,  7.4583e-02],\n",
              "                        [ 8.3459e-03, -7.5460e-02, -7.9827e-02],\n",
              "                        [-4.1036e-02,  3.0659e-02,  2.5711e-03]],\n",
              "              \n",
              "                       [[ 1.9166e-02,  9.9346e-02,  4.8956e-02],\n",
              "                        [ 2.2665e-02, -2.1327e-02,  4.9864e-02],\n",
              "                        [ 3.8563e-02, -9.4879e-02, -6.2266e-02]],\n",
              "              \n",
              "                       [[ 3.5381e-03,  3.9997e-02,  5.1282e-02],\n",
              "                        [-6.2748e-02, -1.0458e-01, -5.4909e-03],\n",
              "                        [-1.2050e-02,  3.0588e-02, -2.8988e-02]],\n",
              "              \n",
              "                       [[ 8.0588e-02,  7.0333e-03,  7.6975e-02],\n",
              "                        [-7.3398e-02,  4.2167e-02,  1.2560e-02],\n",
              "                        [-5.2720e-02,  5.2256e-02, -1.0372e-01]],\n",
              "              \n",
              "                       [[ 8.5220e-02,  8.4947e-03,  1.0178e-02],\n",
              "                        [ 4.8746e-02,  8.7503e-03,  4.5184e-02],\n",
              "                        [ 6.7063e-02, -8.2268e-02,  6.9735e-02]],\n",
              "              \n",
              "                       [[-1.5784e-02, -2.4513e-02,  2.1217e-02],\n",
              "                        [ 8.2446e-02, -5.7302e-02, -7.1039e-02],\n",
              "                        [ 6.5418e-02, -4.9507e-02,  3.3937e-02]],\n",
              "              \n",
              "                       [[-1.5530e-02,  2.9014e-02,  8.0439e-02],\n",
              "                        [-5.3421e-02, -5.1151e-02,  5.1716e-02],\n",
              "                        [ 5.7714e-03, -1.1601e-02, -9.2590e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 8.9309e-02, -3.9919e-03, -1.9415e-02],\n",
              "                        [-4.3269e-02, -2.0801e-02,  5.1233e-02],\n",
              "                        [-2.4227e-03,  9.0147e-02, -6.0858e-03]],\n",
              "              \n",
              "                       [[-1.5122e-02,  5.9498e-02, -2.7275e-03],\n",
              "                        [-2.1039e-02,  3.5231e-02,  8.3129e-02],\n",
              "                        [ 2.6305e-02,  7.3398e-02,  6.8309e-02]],\n",
              "              \n",
              "                       [[ 2.9810e-02,  3.6650e-02,  3.4014e-02],\n",
              "                        [ 1.0934e-02,  8.9675e-02,  9.7308e-02],\n",
              "                        [ 3.7524e-02, -5.2640e-03,  9.4509e-02]],\n",
              "              \n",
              "                       [[-8.2042e-02,  7.7453e-02,  5.5849e-02],\n",
              "                        [ 6.7687e-02, -8.0992e-03, -7.8646e-02],\n",
              "                        [ 7.5193e-02, -4.6091e-02,  2.7734e-02]],\n",
              "              \n",
              "                       [[ 5.9719e-02, -9.8508e-02,  6.9954e-03],\n",
              "                        [-3.7444e-02,  7.4815e-02, -6.7114e-02],\n",
              "                        [ 6.4001e-02,  6.5730e-02,  5.8156e-02]],\n",
              "              \n",
              "                       [[ 1.0119e-01,  1.5964e-02, -9.5541e-02],\n",
              "                        [ 7.5248e-02,  9.6499e-03,  2.0918e-03],\n",
              "                        [-1.0041e-01, -2.3691e-02, -5.1162e-02]],\n",
              "              \n",
              "                       [[ 1.0324e-01,  7.5054e-02,  7.8634e-02],\n",
              "                        [ 7.2188e-02, -6.5340e-02, -4.5270e-02],\n",
              "                        [-4.1252e-02, -4.2257e-02,  8.2054e-02]],\n",
              "              \n",
              "                       [[ 3.5815e-02,  8.4470e-02, -4.9309e-03],\n",
              "                        [-9.3965e-02, -3.0582e-02,  7.4081e-02],\n",
              "                        [ 6.4174e-02,  3.2632e-02, -3.0919e-02]],\n",
              "              \n",
              "                       [[-9.8386e-02, -5.6639e-02,  5.4958e-02],\n",
              "                        [-4.2518e-02,  5.0421e-02,  2.8781e-02],\n",
              "                        [-4.0486e-02,  6.4202e-02, -3.3871e-02]],\n",
              "              \n",
              "                       [[-3.5020e-03, -4.0152e-02, -9.9988e-02],\n",
              "                        [ 1.6996e-02,  3.0460e-02, -5.3072e-02],\n",
              "                        [ 6.4663e-02, -9.4558e-02, -1.0161e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-6.5106e-02, -3.6430e-02, -1.1707e-02],\n",
              "                        [-2.0370e-02,  4.8108e-02, -9.2510e-02],\n",
              "                        [ 1.5521e-02,  1.8254e-03,  2.7842e-02]],\n",
              "              \n",
              "                       [[ 1.0479e-01,  6.4874e-02, -5.8366e-02],\n",
              "                        [-8.6378e-02, -2.5520e-02, -5.2876e-02],\n",
              "                        [ 3.6820e-02,  9.6628e-04,  8.4783e-02]],\n",
              "              \n",
              "                       [[ 4.1405e-02, -1.9382e-02,  3.6229e-03],\n",
              "                        [ 2.5244e-02, -1.3080e-02,  8.5058e-02],\n",
              "                        [-8.2420e-02,  5.1377e-02, -6.7192e-02]],\n",
              "              \n",
              "                       [[-9.2347e-02, -2.1640e-02,  5.1366e-02],\n",
              "                        [ 7.4478e-02,  2.6452e-02, -9.1104e-03],\n",
              "                        [-5.9092e-03, -4.2731e-02, -9.4592e-03]],\n",
              "              \n",
              "                       [[-7.2831e-03,  8.9699e-02,  6.1690e-02],\n",
              "                        [-8.4351e-02,  4.3605e-04, -6.4834e-02],\n",
              "                        [-1.6733e-02, -8.3776e-02,  2.7402e-02]],\n",
              "              \n",
              "                       [[-7.6008e-02,  1.0406e-01,  7.9605e-02],\n",
              "                        [-7.2559e-02, -9.9239e-02,  4.1128e-03],\n",
              "                        [-2.9425e-02,  3.0945e-02, -7.1353e-02]],\n",
              "              \n",
              "                       [[ 4.3148e-02, -9.1047e-02, -5.5632e-02],\n",
              "                        [-5.5414e-02,  5.1007e-02, -2.7597e-03],\n",
              "                        [-1.0130e-01, -6.0201e-02, -4.8781e-02]],\n",
              "              \n",
              "                       [[-9.7802e-02,  1.3497e-02,  3.7561e-02],\n",
              "                        [-1.9340e-02, -4.1947e-02, -6.3926e-04],\n",
              "                        [-8.3725e-02, -6.4184e-02, -2.4040e-03]],\n",
              "              \n",
              "                       [[ 9.3643e-02, -3.2414e-02,  5.2247e-02],\n",
              "                        [-4.1484e-02, -2.8060e-02, -1.0034e-01],\n",
              "                        [ 8.7330e-02,  1.0264e-01, -2.2139e-03]],\n",
              "              \n",
              "                       [[ 6.6974e-02,  8.6219e-02,  5.2359e-02],\n",
              "                        [ 5.4288e-02, -1.0035e-01, -9.9050e-02],\n",
              "                        [-8.0906e-02,  3.2970e-02, -9.1177e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-8.0464e-02, -5.1092e-02, -9.7154e-02],\n",
              "                        [ 1.4203e-04,  1.5207e-02, -6.1686e-02],\n",
              "                        [ 6.9018e-02, -4.0018e-02, -2.9676e-02]],\n",
              "              \n",
              "                       [[ 8.0309e-02,  9.0499e-02, -1.2093e-02],\n",
              "                        [-7.5671e-02, -5.2881e-02,  1.3423e-02],\n",
              "                        [ 6.1790e-02,  5.2477e-02, -4.6547e-02]],\n",
              "              \n",
              "                       [[-9.9650e-02, -9.2249e-02, -3.3537e-02],\n",
              "                        [ 1.3223e-03, -4.7347e-02, -8.3348e-02],\n",
              "                        [ 1.1109e-02, -8.3668e-02, -8.0946e-02]],\n",
              "              \n",
              "                       [[-8.5692e-02, -2.8563e-02,  9.3104e-02],\n",
              "                        [ 4.1207e-02, -1.2498e-02,  2.1694e-02],\n",
              "                        [ 4.1975e-02,  6.1414e-04, -8.5020e-02]],\n",
              "              \n",
              "                       [[-6.4944e-02, -7.1610e-02, -2.6766e-03],\n",
              "                        [-9.6492e-02, -1.9166e-02, -3.8545e-02],\n",
              "                        [ 1.0345e-01,  8.5679e-02,  6.1227e-02]],\n",
              "              \n",
              "                       [[ 5.9116e-03, -3.4129e-02,  2.6887e-02],\n",
              "                        [-7.2830e-02, -4.4957e-02, -2.1175e-02],\n",
              "                        [-2.4766e-02, -9.9854e-02,  4.1903e-02]],\n",
              "              \n",
              "                       [[ 8.6803e-02, -5.8141e-02,  2.8415e-02],\n",
              "                        [-1.2225e-02, -3.8445e-03,  6.1443e-03],\n",
              "                        [ 9.1346e-02,  1.4124e-02, -6.6690e-02]],\n",
              "              \n",
              "                       [[-3.7917e-02,  5.1495e-02,  3.2893e-02],\n",
              "                        [ 2.0487e-03, -1.3912e-02, -4.1012e-02],\n",
              "                        [-3.7413e-02, -5.5602e-02,  1.7273e-02]],\n",
              "              \n",
              "                       [[ 2.9603e-02,  8.0717e-02, -2.3813e-02],\n",
              "                        [ 7.5461e-03,  6.8125e-02,  4.5852e-02],\n",
              "                        [ 1.3544e-02,  3.2390e-02,  5.4714e-03]],\n",
              "              \n",
              "                       [[-9.0419e-02,  4.0636e-03, -2.3040e-02],\n",
              "                        [ 9.5123e-02,  9.5145e-02,  2.0912e-02],\n",
              "                        [ 9.4215e-02, -5.4288e-02,  9.1619e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 9.0756e-02, -4.0288e-03, -8.4592e-02],\n",
              "                        [-3.4015e-02, -2.8189e-02,  1.7411e-03],\n",
              "                        [-9.5569e-02,  1.9535e-02, -4.3839e-02]],\n",
              "              \n",
              "                       [[-2.6989e-02, -5.4443e-02, -2.2255e-02],\n",
              "                        [-9.7896e-02, -5.5885e-02,  9.7108e-03],\n",
              "                        [ 6.9072e-02,  9.5790e-02, -7.9737e-02]],\n",
              "              \n",
              "                       [[ 4.4264e-02, -5.9419e-02, -8.1498e-02],\n",
              "                        [-4.6417e-03, -6.0468e-02, -9.0783e-02],\n",
              "                        [-9.8509e-02, -7.0556e-02,  8.6619e-02]],\n",
              "              \n",
              "                       [[ 5.8788e-02, -4.1726e-02, -7.0553e-02],\n",
              "                        [-8.1085e-02, -6.2246e-02, -4.3376e-02],\n",
              "                        [ 6.3308e-02,  3.4496e-02, -4.0622e-02]],\n",
              "              \n",
              "                       [[ 7.2567e-02, -6.5484e-02, -8.5876e-02],\n",
              "                        [ 2.3006e-02, -5.8123e-02,  2.9987e-02],\n",
              "                        [ 8.9306e-02, -4.9849e-02, -7.3556e-02]],\n",
              "              \n",
              "                       [[ 3.9676e-02, -9.5200e-02,  9.4044e-02],\n",
              "                        [-4.9780e-02,  5.0961e-02, -8.3818e-02],\n",
              "                        [-7.1348e-02,  1.1611e-02,  3.7463e-02]],\n",
              "              \n",
              "                       [[ 8.1734e-02,  8.8158e-02, -6.0623e-03],\n",
              "                        [-1.3552e-02,  1.7424e-02, -2.4486e-02],\n",
              "                        [ 3.5882e-03, -9.9828e-02, -8.6531e-02]],\n",
              "              \n",
              "                       [[ 7.2233e-02, -6.1597e-02,  8.3008e-02],\n",
              "                        [ 1.1568e-02,  2.5676e-02,  9.5804e-02],\n",
              "                        [-5.8628e-02, -1.6640e-02,  1.8675e-02]],\n",
              "              \n",
              "                       [[ 3.6012e-02, -1.0259e-01,  3.7464e-02],\n",
              "                        [-6.2163e-02,  1.3846e-02,  7.1315e-02],\n",
              "                        [-1.0500e-02, -3.3346e-03, -7.8757e-03]],\n",
              "              \n",
              "                       [[ 8.7962e-02,  5.9907e-02,  1.7727e-02],\n",
              "                        [-6.3437e-02, -5.7241e-02,  8.3964e-02],\n",
              "                        [ 7.5834e-02,  6.1033e-02, -8.2189e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 8.2092e-02, -1.0076e-02,  7.7661e-02],\n",
              "                        [ 9.1553e-02,  1.1554e-02, -4.3863e-02],\n",
              "                        [ 9.9153e-02, -5.4931e-02,  6.8876e-02]],\n",
              "              \n",
              "                       [[-1.0108e-01, -3.3153e-02, -9.1902e-02],\n",
              "                        [-4.7284e-02,  4.4759e-02, -7.5529e-02],\n",
              "                        [-9.1158e-02,  7.5371e-02,  5.6270e-02]],\n",
              "              \n",
              "                       [[-1.1527e-03, -7.4309e-02, -2.7927e-02],\n",
              "                        [-3.4129e-02,  6.5100e-02, -3.4478e-02],\n",
              "                        [-3.0360e-02, -7.4720e-02, -4.9646e-02]],\n",
              "              \n",
              "                       [[ 5.7074e-02,  6.7914e-02,  1.5315e-02],\n",
              "                        [-3.9549e-02,  1.0124e-01,  2.0806e-02],\n",
              "                        [-4.0688e-02, -3.6535e-02, -1.4752e-02]],\n",
              "              \n",
              "                       [[ 4.9974e-02,  3.8555e-02,  7.6418e-02],\n",
              "                        [-4.7494e-03,  8.7183e-02, -4.2816e-02],\n",
              "                        [-4.8547e-02, -3.8927e-02, -9.8896e-02]],\n",
              "              \n",
              "                       [[-6.9195e-02, -9.5382e-02, -6.2294e-03],\n",
              "                        [ 9.9374e-04, -2.7358e-02, -7.2035e-02],\n",
              "                        [ 9.5637e-02, -3.4926e-02,  5.0233e-02]],\n",
              "              \n",
              "                       [[ 7.3408e-02, -6.9292e-02, -1.3179e-02],\n",
              "                        [ 6.0923e-02,  1.0218e-01, -1.3299e-02],\n",
              "                        [ 7.6382e-02, -8.2732e-02, -6.8489e-02]],\n",
              "              \n",
              "                       [[ 8.6682e-02, -9.9801e-03,  1.0414e-01],\n",
              "                        [ 7.6651e-03, -4.3714e-02,  1.0011e-01],\n",
              "                        [ 9.2179e-02,  9.7826e-03, -6.3900e-02]],\n",
              "              \n",
              "                       [[-4.5639e-03, -5.0693e-02,  7.6810e-02],\n",
              "                        [ 4.8829e-03,  2.2191e-02,  6.3927e-02],\n",
              "                        [ 3.4916e-02, -6.5803e-02,  8.7566e-02]],\n",
              "              \n",
              "                       [[ 6.4758e-02, -6.5073e-02,  7.9700e-02],\n",
              "                        [ 2.9905e-02, -2.0750e-02, -7.5385e-02],\n",
              "                        [-1.7490e-02, -1.0335e-01,  6.0163e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 7.6343e-02, -3.0347e-02,  9.7720e-02],\n",
              "                        [-3.9032e-02,  1.8051e-02, -7.3459e-02],\n",
              "                        [-4.4565e-03,  4.2610e-02,  4.5403e-02]],\n",
              "              \n",
              "                       [[-3.5346e-03, -5.3154e-02,  7.3680e-02],\n",
              "                        [ 6.9788e-02,  1.6916e-02, -4.8475e-02],\n",
              "                        [ 2.2349e-02,  2.8186e-04,  9.6302e-02]],\n",
              "              \n",
              "                       [[ 1.5621e-02,  8.1301e-03,  7.2057e-03],\n",
              "                        [ 5.6079e-02, -1.3024e-03,  9.0351e-02],\n",
              "                        [ 5.4917e-02, -7.9650e-02, -1.2070e-06]],\n",
              "              \n",
              "                       [[-8.9472e-02, -8.0934e-02,  2.0480e-02],\n",
              "                        [ 2.3687e-02, -9.2246e-03,  1.0019e-01],\n",
              "                        [-5.6627e-02, -4.4176e-02, -1.6881e-02]],\n",
              "              \n",
              "                       [[ 6.3911e-04, -8.9284e-03,  9.4909e-02],\n",
              "                        [-4.4519e-02, -5.5137e-02,  9.0599e-03],\n",
              "                        [ 7.9171e-02,  2.5019e-02,  5.6787e-02]],\n",
              "              \n",
              "                       [[ 2.0406e-02,  8.9839e-02,  6.3311e-02],\n",
              "                        [ 7.5428e-02, -1.4198e-02, -8.7268e-02],\n",
              "                        [-5.0002e-02,  3.5910e-02,  7.3950e-02]],\n",
              "              \n",
              "                       [[-4.1184e-02,  8.7218e-02,  1.5150e-02],\n",
              "                        [ 4.1869e-04,  4.1093e-03, -1.8623e-02],\n",
              "                        [ 9.8683e-02,  4.5784e-03,  6.4564e-02]],\n",
              "              \n",
              "                       [[-8.8967e-02, -5.4309e-02,  1.1852e-02],\n",
              "                        [ 8.4169e-02,  5.0184e-02,  2.0076e-02],\n",
              "                        [-1.0414e-01,  1.9816e-03, -6.9581e-02]],\n",
              "              \n",
              "                       [[-9.0006e-02,  1.4414e-02, -6.6693e-02],\n",
              "                        [ 9.5674e-02, -5.7294e-02,  3.3970e-02],\n",
              "                        [ 6.1871e-02, -8.1928e-02,  5.3946e-02]],\n",
              "              \n",
              "                       [[-1.4114e-02,  5.4619e-02,  1.0201e-01],\n",
              "                        [-4.4922e-02, -4.5653e-02,  8.3753e-02],\n",
              "                        [ 1.1722e-02, -1.0513e-02,  7.9971e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-5.0928e-02, -5.2047e-03,  7.2403e-02],\n",
              "                        [ 4.1195e-02, -6.8180e-02,  2.7398e-02],\n",
              "                        [-8.0368e-02, -5.7245e-02,  6.7779e-02]],\n",
              "              \n",
              "                       [[-2.8093e-02, -5.3691e-02,  7.4717e-03],\n",
              "                        [ 2.5759e-02, -6.5524e-02, -7.1084e-02],\n",
              "                        [-1.0209e-01,  2.7236e-02, -6.8013e-02]],\n",
              "              \n",
              "                       [[ 8.0331e-03, -2.3576e-02, -6.8923e-02],\n",
              "                        [-3.3636e-02, -8.1027e-02, -5.5797e-02],\n",
              "                        [-3.2857e-03, -9.0116e-02, -9.2447e-02]],\n",
              "              \n",
              "                       [[ 7.8958e-02,  9.9188e-03, -4.6618e-02],\n",
              "                        [-3.5047e-03,  7.8168e-02, -8.7939e-02],\n",
              "                        [-5.5886e-02, -7.6226e-02, -7.6634e-03]],\n",
              "              \n",
              "                       [[-3.6274e-03, -8.2146e-02,  7.3163e-02],\n",
              "                        [-8.0946e-02,  9.8414e-02, -7.2560e-02],\n",
              "                        [-1.4446e-02,  1.9710e-02, -4.6852e-02]],\n",
              "              \n",
              "                       [[ 9.6939e-02, -7.2673e-02, -5.8427e-03],\n",
              "                        [-7.7398e-02,  2.9261e-02,  8.9871e-02],\n",
              "                        [ 9.7776e-02,  1.2514e-02, -5.2773e-02]],\n",
              "              \n",
              "                       [[ 1.0244e-01,  7.8667e-03,  7.1317e-02],\n",
              "                        [-5.4751e-02, -4.8920e-02, -8.7504e-02],\n",
              "                        [ 9.6990e-02,  1.7486e-02, -7.5704e-02]],\n",
              "              \n",
              "                       [[ 9.0535e-03, -4.5211e-02,  5.2659e-03],\n",
              "                        [ 3.4988e-02, -5.2308e-02,  1.8394e-02],\n",
              "                        [-6.6553e-02,  2.0312e-02, -1.0178e-01]],\n",
              "              \n",
              "                       [[ 1.6797e-02,  1.0473e-01,  9.7094e-02],\n",
              "                        [ 3.8451e-02,  7.7563e-02,  1.0248e-01],\n",
              "                        [ 2.9870e-02,  3.5156e-02,  1.3707e-02]],\n",
              "              \n",
              "                       [[ 9.3322e-02,  9.0551e-02, -4.9570e-02],\n",
              "                        [-4.3333e-03, -5.3110e-02,  3.7824e-02],\n",
              "                        [-1.0214e-01,  3.7301e-02, -2.8929e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 3.8227e-02,  3.2899e-02, -5.2454e-02],\n",
              "                        [ 5.4687e-02,  4.4762e-02, -8.9602e-02],\n",
              "                        [ 1.0517e-01,  9.0731e-02,  6.5584e-02]],\n",
              "              \n",
              "                       [[-1.0699e-02,  3.7345e-02, -5.7028e-02],\n",
              "                        [-3.5818e-02,  4.9749e-02,  4.6925e-02],\n",
              "                        [ 4.1741e-02, -1.0053e-01,  8.7350e-02]],\n",
              "              \n",
              "                       [[-4.4028e-02,  9.1223e-02,  8.6852e-02],\n",
              "                        [ 3.9070e-02,  1.0502e-01,  6.0528e-02],\n",
              "                        [ 6.1821e-02, -3.5794e-02,  9.7766e-02]],\n",
              "              \n",
              "                       [[ 2.7627e-02,  6.2280e-02, -2.3834e-02],\n",
              "                        [ 7.6340e-02,  9.3509e-02, -8.0770e-02],\n",
              "                        [ 8.6415e-02, -6.9664e-02, -7.2571e-02]],\n",
              "              \n",
              "                       [[-8.8089e-02,  3.0459e-02, -7.9144e-02],\n",
              "                        [-3.9680e-02, -5.2988e-02,  2.8172e-02],\n",
              "                        [-1.0349e-01, -4.8324e-02,  7.7112e-04]],\n",
              "              \n",
              "                       [[ 9.4660e-03, -4.7605e-02,  3.7764e-02],\n",
              "                        [-6.9544e-02, -8.9270e-02, -1.4986e-02],\n",
              "                        [-5.6989e-02,  6.6443e-02, -7.2049e-02]],\n",
              "              \n",
              "                       [[-8.8494e-03,  4.3782e-02, -9.2311e-02],\n",
              "                        [ 8.1599e-02, -4.7895e-02, -2.8684e-02],\n",
              "                        [-6.4480e-02, -3.9279e-02, -4.0645e-02]],\n",
              "              \n",
              "                       [[-9.3801e-02,  3.6019e-02, -3.3768e-04],\n",
              "                        [ 1.0311e-01,  7.1117e-02,  9.1699e-02],\n",
              "                        [ 3.1014e-02,  5.5388e-02,  9.8704e-02]],\n",
              "              \n",
              "                       [[ 8.6545e-02, -8.0996e-02, -2.3636e-02],\n",
              "                        [-1.0166e-01,  3.9877e-03, -3.7229e-02],\n",
              "                        [ 9.1486e-02,  1.6666e-02,  1.1601e-03]],\n",
              "              \n",
              "                       [[-7.6248e-02, -8.2718e-02,  1.6594e-02],\n",
              "                        [-5.2376e-02, -4.8409e-02,  7.3938e-02],\n",
              "                        [-5.4952e-02, -4.6918e-02,  8.0934e-02]]]])),\n",
              "             ('conv_block_1.2.bias',\n",
              "              tensor([ 0.0412, -0.0599,  0.0319,  0.0531, -0.0936,  0.0197,  0.0241, -0.0041,\n",
              "                       0.1011, -0.0697])),\n",
              "             ('classifier.1.weight', tensor([], size=(10, 0))),\n",
              "             ('classifier.1.bias',\n",
              "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_2.state_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1 Stepping through `nn.Conv2d()`\n",
        "\n",
        "See the documentation for `nn.Conv2d()` here - https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image batch shape: torch.Size([32, 3, 64, 64])\n",
            "Single image shape: torch.Size([3, 64, 64])\n",
            "Test image:\n",
            " tensor([[[ 1.9269,  1.4873,  0.9007,  ...,  1.8446, -1.1845,  1.3835],\n",
            "         [ 1.4451,  0.8564,  2.2181,  ...,  0.3399,  0.7200,  0.4114],\n",
            "         [ 1.9312,  1.0119, -1.4364,  ..., -0.5558,  0.7043,  0.7099],\n",
            "         ...,\n",
            "         [-0.5610, -0.4830,  0.4770,  ..., -0.2713, -0.9537, -0.6737],\n",
            "         [ 0.3076, -0.1277,  0.0366,  ..., -2.0060,  0.2824, -0.8111],\n",
            "         [-1.5486,  0.0485, -0.7712,  ..., -0.1403,  0.9416, -0.0118]],\n",
            "\n",
            "        [[-0.5197,  1.8524,  1.8365,  ...,  0.8935, -1.5114, -0.8515],\n",
            "         [ 2.0818,  1.0677, -1.4277,  ...,  1.6612, -2.6223, -0.4319],\n",
            "         [-0.1010, -0.4388, -1.9775,  ...,  0.2106,  0.2536, -0.7318],\n",
            "         ...,\n",
            "         [ 0.2779,  0.7342, -0.3736,  ..., -0.4601,  0.1815,  0.1850],\n",
            "         [ 0.7205, -0.2833,  0.0937,  ..., -0.1002, -2.3609,  2.2465],\n",
            "         [-1.3242, -0.1973,  0.2920,  ...,  0.5409,  0.6940,  1.8563]],\n",
            "\n",
            "        [[-0.7978,  1.0261,  1.1465,  ...,  1.2134,  0.9354, -0.0780],\n",
            "         [-1.4647, -1.9571,  0.1017,  ..., -1.9986, -0.7409,  0.7011],\n",
            "         [-1.3938,  0.8466, -1.7191,  ..., -1.1867,  0.1320,  0.3407],\n",
            "         ...,\n",
            "         [ 0.8206, -0.3745,  1.2499,  ..., -0.0676,  0.0385,  0.6335],\n",
            "         [-0.5589, -0.3393,  0.2347,  ...,  2.1181,  2.4569,  1.3083],\n",
            "         [-0.4092,  1.5199,  0.2401,  ..., -0.2558,  0.7870,  0.9924]]])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Create a batch of images\n",
        "images = torch.randn(size=(32, 3, 64, 64))\n",
        "test_image = images[0]\n",
        "\n",
        "print(f\"Image batch shape: {images.shape}\")\n",
        "print(f\"Single image shape: {test_image.shape}\")\n",
        "print(f\"Test image:\\n {test_image}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 62, 62])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a single conv2d layer\n",
        "conv_layer = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3, stride=1, padding=0)\n",
        "\n",
        "# Pass the data through the convolutional layer\n",
        "conv_output = conv_layer(test_image)\n",
        "conv_output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 Stepping through `nn.MaxPool2d()`\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cuda",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
